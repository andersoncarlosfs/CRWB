{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning unsig the UEC FOOD-256 \n",
    "\n",
    "This notebook will be used to build a model to classifiy dishes with a pre-trained [ImageNet](http://www.image-net.org/) model from the MXNet [model zoo](http://data.mxnet.io/models/) and the  [UEC FOOD 256](http://foodcam.mobi/dataset256.zip) dataset. \n",
    "\n",
    "All of the network’s weights will be updated and also replaced in the last fully-connected layer with the new number of output classes by a smaller learning rate. For more in depth reading on fine-tuning with MXNet check this [tutorial](http://mxnet.io/how_to/finetune.html) and for more details on the how CNN's work check out [CS231n course](http://cs231n.github.io/convolutional-networks/#overview) and [MNIST example](https://github.com/dmlc/mxnet-notebooks/blob/master/python/tutorials/mnist.ipynb) with MXNet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "# download function\n",
    "import os, urllib\n",
    "\n",
    "def download(url, location):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(file_name):\n",
    "        urllib.urlretrieve(url, os.path.join(filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Set the root path and the temp path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = \"/media/\"\n",
    "temp = os.path.join(root, \"sf_Temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Set the dataset path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.- Download the dataset [UEC FOOD 256](http://foodcam.mobi/dataset256.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download(\"http://foodcam.mobi/dataset256.zip\", temp)\n",
    "\n",
    "#dataset = os.path.join(root, \"sf_Datasets/UECFOOD-256.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.- Extract the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "\n",
    "#archiver = zipfile.ZipFile(dataset, 'r')\n",
    "#archiver.extractall(temp)\n",
    "#archiver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = os.path.join(root, \"sf_Datasets/UECFOOD-256\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Create two folders: \"train\" and \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "train = os.path.join(temp, \"train\")\n",
    "\n",
    "if os.path.exists(train):\n",
    "    shutil.rmtree(train)\n",
    "    \n",
    "os.makedirs(train)\n",
    "    \n",
    "validation = os.path.join(temp, \"validation\")\n",
    "\n",
    "if os.path.exists(validation):\n",
    "    shutil.rmtree(validation)\n",
    "\n",
    "os.makedirs(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1- Create additonal directories to get a directory structure as shown below:\n",
    "\n",
    "```\n",
    "    train/\n",
    "\n",
    "    ├── 0category\n",
    "    ├── ..category\n",
    "    └── icategory\n",
    "\n",
    "    validation/\n",
    "\n",
    "    ├── 0category\n",
    "    ├── ..category\n",
    "    └── icategory\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Move all data into train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2, imghdr\n",
    "import pandas as pd\n",
    "\n",
    "#metafile = \"category.txt\" \n",
    "\n",
    "#path = os.path.join(dataset, metafile)\n",
    "#if os.path.isfile(path):\n",
    "    #shutil.copy2(path, os.path.join(train, metafile))\n",
    "\n",
    "metafile = \"bb_info.txt\"  \n",
    "\n",
    "for category, categories, files in os.walk(dataset):\n",
    "    path = os.path.join(category, metafile)\n",
    "    df = None\n",
    "    if os.path.isfile(path):\n",
    "        df = pd.read_csv(os.path.join(category, metafile), delim_whitespace = True, index_col = 0)\n",
    "        #shutil.copy2(path, os.path.join(category, metafile))\n",
    "    for document in files:\n",
    "        path = os.path.join(category, document)\n",
    "        if imghdr.what(path) is not None:\n",
    "            image = cv2.imread(os.path.join(category, document))\n",
    "            name = os.path.splitext(document)[0]\n",
    "            boxes = df.loc[[int(name)]]\n",
    "            for i, (index, box) in enumerate(boxes.iterrows()): \n",
    "                x1 = box.loc[\"x1\"]\n",
    "                x2 = box.loc[\"x2\"]\n",
    "                y1 = box.loc[\"y1\"]\n",
    "                y2 = box.loc[\"y2\"]\n",
    "                cropped = image[y1:y2, x1:x2];\n",
    "                cv2.imwrite(os.path.join(train, os.path.basename(category), str(i) + document), cropped)\n",
    "        #else:\n",
    "            #shutil.copy2(path, os.path.join(train, os.path.basename(category)))\n",
    "    for directory in categories:\n",
    "        path = os.path.join(train, directory)\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.- Move a percentage of the data in to the validation directory to create the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 20%\n",
    "percentage = 20.0\n",
    "      \n",
    "for category, categories, files in os.walk(train):\n",
    "    size = int(len(files) / percentage)\n",
    "    for name in random.sample(files, size):\n",
    "        if imghdr.what(os.path.join(train, category, name)) is not None:\n",
    "            shutil.move(os.path.join(category, name), os.path.join(validation, os.path.basename(category)))\n",
    "    for name in categories:\n",
    "        directory = os.path.join(validation, name)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.- Create a list for training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "    \n",
    "im2rec = os.path.join(os.path.dirname(mx.__file__), \"tools/im2rec.py\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "trainning_list = os.path.join(train, \"train.lst\")\n",
    "\n",
    "if os.path.isfile(im2rec):\n",
    "    if os.path.exists(train):\n",
    "        subprocess.call([\"python\", im2rec, \"--list\", \"True\", \"--recursive\",\"True\", trainninglist, train])\n",
    "\n",
    "validation_list = os.path.join(validation, \"validation.lst\")        \n",
    "        \n",
    "if os.path.isfile(im2rec):\n",
    "    if os.path.exists(validation):\n",
    "        subprocess.call([\"python\", im2rec, \"--list\",\"True\", \"--recursive\", \"True\", validationlist, validation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.- Convert the images in to MXNet RecordIO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(im2rec):\n",
    "    if os.path.exists(train):\n",
    "        subprocess.call([\"python\", im2rec, \"--resize\", \"224\", \"--quality\",\"90\", \"--num-thread\", \"16\", trainninglist, train])\n",
    "\n",
    "if os.path.isfile(im2rec):\n",
    "    if os.path.exists(validation):\n",
    "        subprocess.call([\"python\", im2rec, \"--resize\", \"224\", \"--quality\", \"90\", \"--num-thread\", \"16\", validationlist, validation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The data_train.rec and data_validation.rec files should be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/sf_Temp/train/94/215608.jpg\n",
      "/media/sf_Temp/train/94/315608.jpg\n",
      "/media/sf_Temp/train/94/415608.jpg\n",
      "/media/sf_Temp/train/94/014926.jpg\n",
      "/media/sf_Temp/train/94/015757.jpg\n",
      "/media/sf_Temp/train/94/015911.jpg\n",
      "/media/sf_Temp/train/94/015941.jpg\n",
      "/media/sf_Temp/train/98/016021.jpg\n",
      "/media/sf_Temp/train/98/014814.jpg\n",
      "/media/sf_Temp/train/98/015717.jpg\n",
      "/media/sf_Temp/train/99/05135.jpg\n",
      "/media/sf_Temp/train/31/013705.jpg\n",
      "/media/sf_Temp/train/32/115124.jpg\n",
      "/media/sf_Temp/train/32/013999.jpg\n",
      "/media/sf_Temp/train/32/015176.jpg\n",
      "/media/sf_Temp/train/32/015415.jpg\n",
      "/media/sf_Temp/train/35/014384.jpg\n",
      "/media/sf_Temp/train/35/015911.jpg\n",
      "/media/sf_Temp/train/35/015941.jpg\n",
      "/media/sf_Temp/train/35/015967.jpg\n",
      "/media/sf_Temp/train/36/0413.jpg\n",
      "/media/sf_Temp/train/36/07077.jpg\n",
      "/media/sf_Temp/train/36/0901.jpg\n",
      "/media/sf_Temp/train/36/0910.jpg\n",
      "/media/sf_Temp/train/36/0990.jpg\n",
      "/media/sf_Temp/train/36/028.jpg\n",
      "/media/sf_Temp/train/36/015440.jpg\n",
      "/media/sf_Temp/train/36/015613.jpg\n",
      "/media/sf_Temp/train/36/015695.jpg\n",
      "/media/sf_Temp/train/36/015705.jpg\n",
      "/media/sf_Temp/train/36/015741.jpg\n",
      "/media/sf_Temp/train/36/015849.jpg\n",
      "/media/sf_Temp/train/36/015878.jpg\n",
      "/media/sf_Temp/train/36/015973.jpg\n",
      "/media/sf_Temp/train/36/014526.jpg\n",
      "/media/sf_Temp/train/36/014762.jpg\n",
      "/media/sf_Temp/train/36/014763.jpg\n",
      "/media/sf_Temp/train/36/014768.jpg\n",
      "/media/sf_Temp/train/36/015085.jpg\n",
      "/media/sf_Temp/train/36/015104.jpg\n",
      "/media/sf_Temp/train/36/015215.jpg\n",
      "/media/sf_Temp/train/36/015259.jpg\n",
      "/media/sf_Temp/train/36/015366.jpg\n",
      "/media/sf_Temp/train/36/015373.jpg\n",
      "/media/sf_Temp/train/36/013701.jpg\n",
      "/media/sf_Temp/train/36/013705.jpg\n",
      "/media/sf_Temp/train/36/013726.jpg\n",
      "/media/sf_Temp/train/36/013731.jpg\n",
      "/media/sf_Temp/train/36/013733.jpg\n",
      "/media/sf_Temp/train/36/013746.jpg\n",
      "/media/sf_Temp/train/36/013747.jpg\n",
      "/media/sf_Temp/train/36/013748.jpg\n",
      "/media/sf_Temp/train/36/013754.jpg\n",
      "/media/sf_Temp/train/36/013755.jpg\n",
      "/media/sf_Temp/train/36/013756.jpg\n",
      "/media/sf_Temp/train/36/013775.jpg\n",
      "/media/sf_Temp/train/36/013779.jpg\n",
      "/media/sf_Temp/train/36/013784.jpg\n",
      "/media/sf_Temp/train/36/013857.jpg\n",
      "/media/sf_Temp/train/36/013985.jpg\n",
      "/media/sf_Temp/train/36/013995.jpg\n",
      "/media/sf_Temp/train/36/014003.jpg\n",
      "/media/sf_Temp/train/36/014239.jpg\n",
      "/media/sf_Temp/train/36/014240.jpg\n",
      "/media/sf_Temp/train/36/014263.jpg\n",
      "/media/sf_Temp/train/36/014264.jpg\n",
      "/media/sf_Temp/train/36/014287.jpg\n",
      "/media/sf_Temp/train/36/014291.jpg\n",
      "/media/sf_Temp/train/36/014295.jpg\n",
      "/media/sf_Temp/train/36/014308.jpg\n",
      "/media/sf_Temp/train/36/014388.jpg\n",
      "/media/sf_Temp/train/36/010708.jpg\n",
      "/media/sf_Temp/train/36/011200.jpg\n",
      "/media/sf_Temp/train/36/011337.jpg\n",
      "/media/sf_Temp/train/36/011874.jpg\n",
      "/media/sf_Temp/train/36/012380.jpg\n",
      "/media/sf_Temp/train/36/012436.jpg\n",
      "/media/sf_Temp/train/36/012456.jpg\n",
      "/media/sf_Temp/train/36/012632.jpg\n",
      "/media/sf_Temp/train/36/013246.jpg\n",
      "/media/sf_Temp/train/38/03694.jpg\n",
      "/media/sf_Temp/train/38/03710.jpg\n",
      "/media/sf_Temp/train/38/03751.jpg\n",
      "/media/sf_Temp/train/38/07321.jpg\n",
      "/media/sf_Temp/train/41/014002.jpg\n",
      "/media/sf_Temp/train/42/013734.jpg\n",
      "/media/sf_Temp/train/42/015302.jpg\n",
      "/media/sf_Temp/train/42/015428.jpg\n",
      "/media/sf_Temp/train/42/015692.jpg\n",
      "/media/sf_Temp/train/44/014003.jpg\n",
      "/media/sf_Temp/train/45/014920.jpg\n",
      "/media/sf_Temp/train/45/015389.jpg\n",
      "/media/sf_Temp/train/46/04499.jpg\n",
      "/media/sf_Temp/train/52/05237.jpg\n",
      "/media/sf_Temp/train/53/013746.jpg\n",
      "/media/sf_Temp/train/53/015650.jpg\n",
      "/media/sf_Temp/train/55/011178.jpg\n",
      "/media/sf_Temp/train/55/014412.jpg\n",
      "/media/sf_Temp/train/55/015311.jpg\n",
      "/media/sf_Temp/train/56/013776.jpg\n",
      "/media/sf_Temp/train/6/012904.jpg\n",
      "/media/sf_Temp/train/60/114289.jpg\n",
      "/media/sf_Temp/train/60/015189.jpg\n",
      "/media/sf_Temp/train/61/06132.jpg\n",
      "/media/sf_Temp/train/63/013724.jpg\n",
      "/media/sf_Temp/train/63/014267.jpg\n",
      "/media/sf_Temp/train/67/013703.jpg\n",
      "/media/sf_Temp/train/67/013731.jpg\n",
      "/media/sf_Temp/train/67/014346.jpg\n",
      "/media/sf_Temp/train/67/014903.jpg\n",
      "/media/sf_Temp/train/67/015259.jpg\n",
      "/media/sf_Temp/train/68/07178.jpg\n",
      "/media/sf_Temp/train/68/07263.jpg\n",
      "/media/sf_Temp/train/68/27032.jpg\n",
      "/media/sf_Temp/train/68/06793.jpg\n",
      "/media/sf_Temp/train/68/06835.jpg\n",
      "/media/sf_Temp/train/69/07370.jpg\n",
      "/media/sf_Temp/train/70/013723.jpg\n",
      "/media/sf_Temp/train/70/013736.jpg\n",
      "/media/sf_Temp/train/70/014397.jpg\n",
      "/media/sf_Temp/train/70/015104.jpg\n",
      "/media/sf_Temp/train/70/015179.jpg\n",
      "/media/sf_Temp/train/70/015286.jpg\n",
      "/media/sf_Temp/train/70/015447.jpg\n",
      "/media/sf_Temp/train/71/015428.jpg\n",
      "/media/sf_Temp/train/71/015692.jpg\n",
      "/media/sf_Temp/train/75/015428.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6788a4c42eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimghdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/os.pyc\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mnew_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/os.pyc\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnondirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mdirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/genericpath.pyc\u001b[0m in \u001b[0;36misdir\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;34m\"\"\"Return true if the pathname refers to an existing directory.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for directory, directories, files in os.walk(train):\n",
    "    for document in files:\n",
    "        path = os.path.join(directory, document)\n",
    "        if imghdr.what(path) is None:\n",
    "            print path\n",
    "            \n",
    "for directory, directories, files in os.walk(validation):\n",
    "    for document in files:\n",
    "        path = os.path.join(directory, document)\n",
    "        if imghdr.what(path) is None:\n",
    "            print document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE\n",
    "\n",
    "The function below returns the data iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Iterators for cats vs dogs dataset\n",
    "\n",
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    trainning_iterator = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = os.path.join(train, \"train.rec\"), \n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    validation_iterator = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = os.path.join(validation, \"validation.lst\"),\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (trainning_iterator, validation_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dowload pre-trained model from the model zoo (ResidualNet152)\n",
    "\n",
    "Download a pre-trained 152-layer ResNet model and load into memory.\n",
    "\n",
    "    Note: If load_checkpoint reports error the downloaded files need to be removed before to try get the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download function\n",
    "def get_model(prefix, epoch, location):\n",
    "    download(prefix + \"-symbol.json\", location)\n",
    "    download(prefix + \"-%04d.params\" % (epoch,), location)\n",
    "\n",
    "get_model(\"http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152\", 0, temp)\n",
    "\n",
    "symbol, arg_params, aux_params = mx.model.load_checkpoint(\"resnet-152\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the model\n",
    "\n",
    "\n",
    "To fine-tune a network, the last fully-connected layer with must be replace by a new one that outputs the desired number of classes. The weights are initialize randomly. Then training will continue normaly. Sometimes it’s common use a smaller learning rate based on the intuition that good result may already be reached.\n",
    "\n",
    "First of all, a function which replaces the the last fully-connected layer for a given network needs to be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fine_tune_model(sym, arg_params, num_classes, layer_name = \"flatten0\"):\n",
    "    \"\"\"\n",
    "    symbol: the pre-trained network symbol\n",
    "    arg_params: the argument parameters of the pre-trained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = sym.get_internals()\n",
    "    net = all_layers[layer_name + \"_output\"]\n",
    "    net = mx.symbol.FullyConnected(data = net, num_hidden = num_classes, name = \"fc1\")\n",
    "    net = mx.symbol.SoftmaxOutput(data = net, name = \"softmax\")\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if \"fc1\" not in k})\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "A fit function that creates an MXNet module instance needs to be defined to bind the data and symbols. \n",
    "\n",
    "init_params is called to randomly initialize parameters\n",
    "\n",
    "set_params is called to replace all parameters except for the last fully-connected layer with pre-trained model.\n",
    "\n",
    "#### Note: change mx.cpu to mx.gpu to run training on GPU (much faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level = logging.DEBUG, format = \"%(asctime)-15s %(message)s\")\n",
    "\n",
    "def fit(sym, arg_params, aux_params, train_iter, val_iter, batch_size, num_pus = 1, num_epoch = 1):\n",
    "    devs = [mx.cpu(i) for i in range(num_pus)] # replace mx.cpu by mx.gpu for GPU training\n",
    "    mod = mx.mod.Module(symbol = new_sym, context = devs)\n",
    "    mod.bind(data_shapes = train_iter.provide_data, label_shapes = train_iter.provide_label)\n",
    "    mod.init_params(initializer = mx.init.Xavier(rnd_type = \"gaussian\", factor_type = \"in\", magnitude = 2))\n",
    "    mod.set_params(new_args, aux_params, allow_missing = True)\n",
    "    mod.fit(\n",
    "        train_iter, \n",
    "        val_iter, \n",
    "        num_epoch = num_epoch,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 10),        \n",
    "        kvstore = \"device\",\n",
    "        optimizer = \"sgd\",\n",
    "        optimizer_params = {\"learning_rate\":0.009},\n",
    "        eval_metri ='acc'\n",
    "    )\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the helper functions are setup and training can to start.\n",
    "Its recommended that to train on a GPU instance, preferably p2.* family. For this notebook an AWS EC2 p2.xlarge, which has one NVIDIA K80 GPU, was considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = 256 # Number of categories\n",
    "batch_per_pu = 4\n",
    "num_pus = 1\n",
    "(new_sym, new_args) = get_fine_tune_model(symbol, arg_params, num_classes)\n",
    "\n",
    "batch_size = batch_per_gpu * num_gpus\n",
    "(train_iter, val_iter) = get_iterators(batch_size)\n",
    "mod = fit(new_sym, new_args, aux_params, train_iter, val_iter, batch_size, num_gpus)\n",
    "metric = mx.metric.Accuracy()\n",
    "mod_score = mod.score(val_iter, metric)\n",
    "print mod_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the newly trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = \"resnet-mxnet-dishes\"\n",
    "epoch = 1\n",
    "\n",
    "mc = mod.save_chekpoint(prefix, epoch)\n",
    "\n",
    "for document in os.listdir(\"./\"):\n",
    "    if (document.startswith(prefix)):\n",
    "        shutil.move(document, temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "dshape = [('data', (1,3,224,224))]\n",
    "\n",
    "def load_model(s_fname, p_fname):\n",
    "    \"\"\"\n",
    "    load model checkpoint from file.\n",
    "    :return: (arg_params, aux_params)\n",
    "    arg_params : dict of str to NDArray\n",
    "        Model parameter, dict of name to NDArray of net's weights.\n",
    "    aux_params : dict of str to NDArray\n",
    "        Model parameter, dict of name to NDArray of net's auxiliary states.\n",
    "    \"\"\"\n",
    "    symbol = mx.symbol.load(s_fname)\n",
    "    save_dict = mx.nd.load(p_fname)\n",
    "    arg_params = {}\n",
    "    aux_params = {}\n",
    "    for k, v in save_dict.items():\n",
    "        tp, name = k.split(':', 1)\n",
    "        if tp == 'arg':\n",
    "            arg_params[name] = v\n",
    "        if tp == 'aux':\n",
    "            aux_params[name] = v\n",
    "    return symbol, arg_params, aux_params\n",
    "       \n",
    "model_symbol = None\n",
    "model_params = None\n",
    "\n",
    "for document in os.listdir(temp):\n",
    "    filename, extension = os.path.splitext(document)\n",
    "    if (filename.startswith(prefix)):\n",
    "        if(extension == \"json\")\n",
    "            model_symbol = document\n",
    "        if(extension == \"params\")\n",
    "            model_params = document\n",
    "\n",
    "symbol, arg_params, aux_params = load_model(model_symbol, model_params)\n",
    "mod = mx.mod.Module(symbol = symbol)\n",
    "\n",
    "# bind the model, set training to False and define the data shape\n",
    "mod.bind(for_training = False, data_shapes = dshape)\n",
    "mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions for an arbitrary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "def preprocess_image(img, show = False):\n",
    "    '''\n",
    "    convert the image to a numpy array\n",
    "    '''\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2) \n",
    "    img = img[np.newaxis, :] \n",
    "    return img\n",
    "\n",
    "url = 'https://cdn.pixabay.com/photo/2016/03/05/19/02/abstract-1238248_640.jpg'\n",
    "request = urllib2.urlopen(url)\n",
    "\n",
    "image = np.asarray(bytearray(req.read()), dtype = \"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "image = preprocess_image(image)\n",
    "\n",
    "mod.forward(Batch([mx.nd.array(image)]))\n",
    "\n",
    "# predict\n",
    "prob = mod.get_outputs()[0].asnumpy()\n",
    "print prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inspecting incorrect labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
